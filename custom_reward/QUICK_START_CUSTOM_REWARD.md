# ğŸ¯ è‡ªå®šä¹‰ Reward ç³»ç»Ÿ - å¿«é€Ÿå¼€å§‹

## ğŸ“¦ ä½ ç°åœ¨æ‹¥æœ‰çš„å·¥å…·

### 1ï¸âƒ£ **äº¤äº’å¼é…ç½®å™¨** (`reward_config_interactive.py`)
- âœ… é€æ¡åˆ—å‡ºæ‰€æœ‰å¯é€‰ reward ç»„ä»¶
- âœ… æä¾› 8 ä¸ªé¢„è®¾æ–¹æ¡ˆ
- âœ… æ”¯æŒå®Œå…¨è‡ªå®šä¹‰é…ç½®
- âœ… ç”Ÿæˆ JSON é…ç½®æ–‡ä»¶

### 2ï¸âƒ£ **è‡ªå®šä¹‰ç¯å¢ƒç±»** (`custom_reward_env.py`)
- âœ… æ”¯æŒåŠ è½½é…ç½®æ–‡ä»¶
- âœ… å®ç°äº†æ‰€æœ‰ reward shaping é€»è¾‘
- âœ… æä¾› reward åˆ†è§£ä¿¡æ¯ï¼ˆbase + shapedï¼‰
- âœ… å®Œå…¨å…¼å®¹ç°æœ‰è®­ç»ƒä»£ç 

### 3ï¸âƒ£ **ä½¿ç”¨ç¤ºä¾‹** (`example_custom_reward.py`)
- âœ… 6 ä¸ªå®Œæ•´ç¤ºä¾‹
- âœ… å±•ç¤ºä¸åŒé…ç½®çš„æ•ˆæœ
- âœ… åŒ…å«è®­ç»ƒç¤ºä¾‹

### 4ï¸âƒ£ **å®Œæ•´æ–‡æ¡£**
- âœ… `REWARD_DESIGN_GUIDE.md` - è®¾è®¡åŸåˆ™å’ŒæŒ‡å—
- âœ… `CAPSULE_AND_GHOST_ANALYSIS.md` - UCB Pacman æœºåˆ¶åˆ†æ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3 æ­¥ï¼‰

### Step 1: è®¾è®¡ä½ çš„ Reward

è¿è¡Œäº¤äº’å¼é…ç½®å™¨ï¼š
```bash
python reward_config_interactive.py
```

**æ¨èæµç¨‹**ï¼š
1. å…ˆé€‰æ‹©ä¸€ä¸ªé¢„è®¾æ–¹æ¡ˆï¼ˆå¦‚"æœ€å°é…ç½®"æˆ–"å¹³è¡¡é…ç½®"ï¼‰
2. æ ¹æ®éœ€è¦å¾®è°ƒå‚æ•°
3. ä¿å­˜ä¸ºé…ç½®æ–‡ä»¶ï¼ˆå¦‚ `my_reward.json`ï¼‰

**8 ä¸ªé¢„è®¾æ–¹æ¡ˆ**ï¼š
- `æœ€å°é…ç½®` - ä»… UCB åŸç”Ÿï¼ŒéªŒè¯åŸºç¡€å­¦ä¹  â­
- `æ— æ—¶é—´æƒ©ç½š` - ç§»é™¤æ¯æ­¥ -1ï¼Œæ¢ç´¢å‹å¥½
- `å Stop é…ç½®` - è§£å†³åœåœ¨åŸåœ°é—®é¢˜
- `åéœ‡è¡é…ç½®` - è§£å†³æ¥å›ç§»åŠ¨é—®é¢˜
- `æ¢ç´¢å¯¼å‘` - é¼“åŠ±è®¿é—®æ–°ä½ç½®
- `å¼•å¯¼å­¦ä¹ ` - æ¥è¿‘ food æœ‰å¥–åŠ± â­
- `å¹³è¡¡é…ç½®` - ç»¼åˆå¤šç§æŠ€æœ¯ â­
- `åŠ¿å‡½æ•°å¡‘é€ ` - ç†è®ºä¿è¯æœ€ä¼˜ç­–ç•¥ä¸å˜ â­â­â­

---

### Step 2: æµ‹è¯•ä½ çš„é…ç½®

è¿è¡Œç¤ºä¾‹è„šæœ¬æµ‹è¯•æ•ˆæœï¼š
```bash
python example_custom_reward.py
```

é€‰æ‹©å¯¹åº”çš„ç¤ºä¾‹æŸ¥çœ‹æ•ˆæœï¼š
- ç¤ºä¾‹ 1: æœ€å°é…ç½®æ¼”ç¤º
- ç¤ºä¾‹ 2: å Stop æ•ˆæœ
- ç¤ºä¾‹ 3: å¼•å¯¼å­¦ä¹ æ•ˆæœï¼ˆçœ‹ reward breakdownï¼‰
- ç¤ºä¾‹ 4: åŠ¿å‡½æ•°å¡‘é€ æ•ˆæœ
- ç¤ºä¾‹ 5: ä»é…ç½®æ–‡ä»¶åŠ è½½
- ç¤ºä¾‹ 6: è®­ç»ƒ MC agent

---

### Step 3: ç”¨äºè®­ç»ƒ

**æ–¹æ³• A: ä¿®æ”¹ `train_mc.py`**

```python
# åœ¨ train_mc.py é¡¶éƒ¨å¯¼å…¥
from pacman_env.envs.custom_reward_env import CustomRewardPacmanEnv

# åœ¨ train_agent() å‡½æ•°ä¸­æ›¿æ¢ç¯å¢ƒåˆ›å»º
def train_agent(...):
    # æ—§ä»£ç :
    # env = PacmanEnv(use_graphics=render, episode_length=max_steps)
    
    # æ–°ä»£ç :
    env = CustomRewardPacmanEnv(
        reward_config_file='my_reward.json',  # ä½ çš„é…ç½®æ–‡ä»¶
        use_graphics=render,
        episode_length=max_steps
    )
    
    # å…¶ä½™ä»£ç ä¸å˜...
```

**æ–¹æ³• B: åˆ›å»ºæ–°çš„è®­ç»ƒè„šæœ¬**

```python
# train_custom_reward.py
from pacman_env.envs.custom_reward_env import CustomRewardPacmanEnv
from agents.mc_agent import MCAgent

# å®šä¹‰é…ç½®
config = {
    'basic_food': 10.0,
    'basic_win': 500.0,
    'basic_time_penalty': -1.0,
    'stop_penalty': -1.0,
    'approach_food_bonus': 0.3,
}

# åˆ›å»ºç¯å¢ƒ
env = CustomRewardPacmanEnv(
    reward_config=config,
    use_graphics=False,
    episode_length=100
)

# è®­ç»ƒï¼ˆä¸åŸæ¥å®Œå…¨ä¸€æ ·ï¼‰
agent = MCAgent(...)
for episode in range(num_episodes):
    obs, info = env.reset(layout='smallClassic.lay')
    for step in range(max_steps):
        legal_actions = env.get_legal_actions()
        action = agent.select_action(obs, legal_actions)
        # ... å…¶ä½™è®­ç»ƒé€»è¾‘ ...
```

---

## ğŸ“Š å¯¹æ¯”å®éªŒå»ºè®®

### å®éªŒ 1: éªŒè¯ Stop é—®é¢˜æ˜¯å¦è§£å†³

```bash
# åŸºçº¿: æœ€å°é…ç½®
python reward_config_interactive.py  # é€‰æ‹© 1 (æœ€å°é…ç½®)
# ä¿å­˜ä¸º baseline.json
python train_mc.py --config baseline.json --episodes 500

# å¯¹æ¯”: å Stop é…ç½®
python reward_config_interactive.py  # é€‰æ‹© 3 (å Stop)
# ä¿å­˜ä¸º anti_stop.json
python train_mc.py --config anti_stop.json --episodes 500
```

**è§‚å¯ŸæŒ‡æ ‡**ï¼š
- Stop åŠ¨ä½œæ¯”ä¾‹æ˜¯å¦ä¸‹é™
- å¹³å‡ episode reward æ˜¯å¦æé«˜
- Win rate æ˜¯å¦æé«˜

---

### å®éªŒ 2: ä¸åŒå¼•å¯¼å¼ºåº¦å¯¹æ¯”

æµ‹è¯•ä¸åŒçš„ `approach_food_bonus` å€¼ï¼š

```python
# é…ç½® A: æ— å¼•å¯¼
{'basic_food': 10.0, 'basic_win': 500.0}

# é…ç½® B: å¼±å¼•å¯¼
{'basic_food': 10.0, 'basic_win': 500.0, 'approach_food_bonus': 0.1}

# é…ç½® C: ä¸­ç­‰å¼•å¯¼
{'basic_food': 10.0, 'basic_win': 500.0, 'approach_food_bonus': 0.3}

# é…ç½® D: å¼ºå¼•å¯¼
{'basic_food': 10.0, 'basic_win': 500.0, 'approach_food_bonus': 0.5}
```

**è§‚å¯ŸæŒ‡æ ‡**ï¼š
- å­¦ä¹ é€Ÿåº¦ï¼ˆå‰ 100 episodes çš„å¹³å‡ rewardï¼‰
- éœ‡è¡é—®é¢˜æ˜¯å¦å‡ºç°
- æœ€ç»ˆç­–ç•¥è´¨é‡

---

### å®éªŒ 3: åŠ¿å‡½æ•° vs æ‰‹åŠ¨å¡‘é€ 

```python
# é…ç½® A: æ‰‹åŠ¨å¡‘é€ 
{
    'basic_food': 10.0,
    'basic_win': 500.0,
    'stop_penalty': -1.0,
    'approach_food_bonus': 0.3,
    'exploration_bonus': 0.1
}

# é…ç½® B: åŠ¿å‡½æ•°å¡‘é€ 
{
    'basic_food': 10.0,
    'basic_win': 500.0,
    'potential_based_shaping': {
        'enabled': True,
        'gamma': 0.99,
        'potential_type': 'nearest_food'
    }
}
```

**ç†è®ºé¢„æµ‹**ï¼š
- åŠ¿å‡½æ•°ä¿è¯æœ€ä¼˜ç­–ç•¥ä¸å˜
- æ‰‹åŠ¨å¡‘é€ å¯èƒ½æ›´å¿«ä½†æœ‰é£é™©

---

## ğŸ” æŸ¥çœ‹ Reward åˆ†è§£

`CustomRewardPacmanEnv` åœ¨ `info` ä¸­æä¾› reward åˆ†è§£ï¼š

```python
obs, reward, terminated, truncated, info = env.step(action)

if 'reward_breakdown' in info:
    print(f"Base reward: {info['reward_breakdown']['base']}")      # UCB åŸç”Ÿ
    print(f"Shaped reward: {info['reward_breakdown']['shaped']}")  # é¢å¤–å¡‘é€ 
    print(f"Total reward: {info['reward_breakdown']['total']}")    # æ€»å’Œ
```

**ç”¨äºè°ƒè¯•**ï¼š
- æ£€æŸ¥ shaping æ˜¯å¦ç”Ÿæ•ˆ
- è§‚å¯Ÿå“ªäº›æ­¥éª¤è·å¾—äº† shaping reward
- éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®

---

## ğŸ“ å®Œæ•´çš„ Reward ç»„ä»¶åˆ—è¡¨

### åŸºç¡€äº‹ä»¶ï¼ˆå»ºè®®ä¿æŒ UCB åŸå€¼ï¼‰
- `basic_food`: +10
- `basic_capsule`: 0
- `basic_ghost_eat`: +200
- `basic_death`: -500
- `basic_win`: +500
- `basic_time_penalty`: -1

### åŠ¨ä½œå¡‘é€ ï¼ˆè§£å†³è¡Œä¸ºé—®é¢˜ï¼‰
- `stop_penalty`: -0.5 ~ -2.0
- `reverse_direction_penalty`: -0.5 ~ -1.0
- `oscillation_penalty`: -2.0 ~ -5.0

### ä½ç½®å¡‘é€ ï¼ˆæ¢ç´¢ç›¸å…³ï¼‰
- `exploration_bonus`: +0.05 ~ +0.2
- `revisit_penalty`: -0.2 ~ -0.5
- `corner_penalty`: -0.5 ~ -1.0

### è·ç¦»å¡‘é€ ï¼ˆå¼•å¯¼å­¦ä¹ ï¼‰
- `approach_food_bonus`: +0.1 ~ +0.5
- `leave_food_penalty`: -0.1 ~ -0.5
- `approach_capsule_bonus`: +0.5
- `ghost_distance_reward`: åŠ¨æ€

### çŠ¶æ€å¡‘é€ ï¼ˆæ•ˆç‡ç›¸å…³ï¼‰
- `food_remaining_penalty`: -0.01
- `progress_reward`: +1.0
- `efficiency_bonus`: +0.5

### é«˜çº§å¡‘é€ ï¼ˆç†è®ºä¿è¯ï¼‰
- `potential_based_shaping`: ç†è®ºæœ€ä¼˜ â­â­â­

---

## âš ï¸ è®¾è®¡åŸåˆ™æé†’

### âœ… é»„é‡‘æ³•åˆ™
1. **Shaping reward < 10% Ã— Basic reward**
2. **ä¿æŒç¨€ç–æ€§** - åŸºç¡€äº‹ä»¶æ˜¯ä¸»ä¿¡å·
3. **é¿å…å†²çª** - ä¸åŒ shaping åº”ä¸€è‡´
4. **é€æ­¥è°ƒæ•´** - ä¸€æ¬¡åªæ”¹ä¸€é¡¹

### âŒ å¸¸è§é™·é˜±
1. `exploration_bonus` è¿‡é«˜ â†’ åˆ·æ¢ç´¢åˆ†
2. `approach_food_bonus` è¿‡é«˜ â†’ éœ‡è¡
3. `stop_penalty` è¿‡å¼º â†’ æ’å¢™ä¸åœ
4. è¿‡åº¦å¡‘é€  â†’ å­¦åˆ° shaping è€Œéä»»åŠ¡

---

## ğŸ“ æ¨èå­¦ä¹ è·¯å¾„

### ç¬¬ 1 å‘¨ï¼šåŸºçº¿éªŒè¯
- ä½¿ç”¨**æœ€å°é…ç½®**è®­ç»ƒ 1000 episodes
- è®°å½•é—®é¢˜ï¼ˆStop åå¥½ï¼Ÿéœ‡è¡ï¼Ÿï¼‰
- ä¸è¦æ€¥äºæ·»åŠ  shaping

### ç¬¬ 2 å‘¨ï¼šé’ˆå¯¹æ€§æ”¹è¿›
- æ ¹æ®é—®é¢˜é€‰æ‹©é¢„è®¾æ–¹æ¡ˆ
- å¯¹æ¯”å®éªŒï¼ˆbaseline vs improvedï¼‰
- åˆ†æ reward breakdown

### ç¬¬ 3 å‘¨ï¼šç²¾ç»†è°ƒå‚
- æµ‹è¯•ä¸åŒ shaping å¼ºåº¦
- æ‰¾åˆ°æœ€ä½³å¹³è¡¡ç‚¹
- åœ¨å¤šä¸ª layout ä¸ŠéªŒè¯

### ç¬¬ 4 å‘¨ï¼šç†è®ºæ–¹æ³•
- å°è¯•**åŠ¿å‡½æ•°å¡‘é€ **
- å¯¹æ¯”æ‰‹åŠ¨å¡‘é€  vs åŠ¿å‡½æ•°
- æ€»ç»“æœ€ä½³å®è·µ

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `REWARD_DESIGN_GUIDE.md` - å®Œæ•´è®¾è®¡æŒ‡å—
- `CAPSULE_AND_GHOST_ANALYSIS.md` - UCB Pacman æœºåˆ¶
- `STOP_ACTION_ANALYSIS_SUMMARY.md` - Stop é—®é¢˜åˆ†æ
- `OSCILLATION_PROBLEM_ANALYSIS.md` - éœ‡è¡é—®é¢˜åˆ†æ

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: é…ç½®æ–‡ä»¶æ”¾åœ¨å“ªé‡Œï¼Ÿ
A: ä¸ `train_mc.py` åŒç›®å½•å³å¯ï¼Œæˆ–ä½¿ç”¨ç»å¯¹è·¯å¾„

### Q2: å¦‚ä½•çŸ¥é“å“ªä¸ªé…ç½®æœ€å¥½ï¼Ÿ
A: è¿è¡Œå¯¹æ¯”å®éªŒï¼Œè§‚å¯Ÿï¼š
- Win rate
- å¹³å‡ reward
- è®­ç»ƒæ›²çº¿ç¨³å®šæ€§
- æœ€ç»ˆç­–ç•¥è´¨é‡

### Q3: åŠ¿å‡½æ•°å¡‘é€ çœŸçš„æ›´å¥½å—ï¼Ÿ
A: ç†è®ºä¸Šæ˜¯çš„ï¼Œä½†å®è·µä¸­å–å†³äºï¼š
- åŠ¿å‡½æ•°è®¾è®¡æ˜¯å¦åˆç†
- Î³ æ˜¯å¦ä¸ agent ä¸€è‡´
- ä»»åŠ¡å¤æ‚åº¦

### Q4: å¯ä»¥åŒæ—¶ç”¨å¤šç§ shaping å—ï¼Ÿ
A: å¯ä»¥ï¼Œä½†è¦æ³¨æ„ï¼š
- é¿å…å†²çªï¼ˆå¦‚åŒæ—¶æƒ©ç½šå’Œå¥–åŠ±åŒä¸€è¡Œä¸ºï¼‰
- æ§åˆ¶æ€»é‡ï¼ˆæ€» shaping ä¸è¶…è¿‡ basic rewardï¼‰
- é€æ­¥æ·»åŠ ï¼ŒéªŒè¯æ•ˆæœ

---

## ğŸ‰ å¼€å§‹ä½ çš„å®éªŒï¼

```bash
# Step 1: è®¾è®¡é…ç½®
python reward_config_interactive.py

# Step 2: æµ‹è¯•æ•ˆæœ
python example_custom_reward.py

# Step 3: å¼€å§‹è®­ç»ƒ
python train_mc.py  # ä¿®æ”¹åçš„ç‰ˆæœ¬
```

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
