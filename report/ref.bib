@ARTICLE{JPEG,
  author={Wallace, G.K.},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={The JPEG still picture compression standard}, 
  year={1992},
  volume={38},
  number={1},
  pages={xviii-xxxiv},
  keywords={Transform coding;Image coding;Digital images;Image storage;Standards development;ISO standards;Gray-scale;Displays;Costs;Facsimile},
  doi={10.1109/30.125072}
}

@ARTICLE{VVC,
  author={Bross, Benjamin and Wang, Ye-Kui and Ye, Yan and Liu, Shan and Chen, Jianle and Sullivan, Gary J. and Ohm, Jens-Rainer},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Overview of the Versatile Video Coding (VVC) Standard and its Applications}, 
  year={2021},
  volume={31},
  number={10},
  pages={3736-3764},
  keywords={Standards;Streaming media;Encoding;Decoding;Transform coding;High efficiency video coding;Tools;Video coding;video compression;standards;H.266;VVC;H.265;HEVC;MPEG;VCEG;JVET},
  doi={10.1109/TCSVT.2021.3101953}
}

@ARTICLE{HEVC,
  author={Sullivan, Gary J. and Ohm, Jens-Rainer and Han, Woo-Jin and Wiegand, Thomas},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Overview of the High Efficiency Video Coding (HEVC) Standard}, 
  year={2012},
  volume={22},
  number={12},
  pages={1649-1668},
  keywords={Video coding;ISO standards;Video compression;MPEG 4 Standard;MPEG standards;Advanced video coding (AVC);H.264;High Efficiency Video Coding (HEVC);Joint Collaborative Team on Video Coding (JCT-VC);Moving Picture Experts Group (MPEG);MPEG-4;standards;Video Coding Experts Group (VCEG);video compression},
  doi={10.1109/TCSVT.2012.2221191}
}

@article{Reeve84Block,
author = {Howard C. Reeve III and Jae S. Lim},
title = {{Reduction Of Blocking Effects In Image Coding}},
volume = {23},
journal = {Optical Engineering},
number = {1},
publisher = {SPIE},
pages = {230134},
keywords = {Tunable filters, Image compression, Image segmentation, Image filtering, Image quality, Quantization, Discontinuities, Optical engineering, Image processing, Image sharpness},
year = {1984},
doi = {10.1117/12.7973248},
URL = {https://doi.org/10.1117/12.7973248}
}

@misc{Ballé17,
      title={End-to-end Optimized Image Compression}, 
      author={Johannes Ballé and Valero Laparra and Eero P. Simoncelli},
      year={2017},
      eprint={1611.01704},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1611.01704}, 
}

@misc{Ballé18,
      title={Variational image compression with a scale hyperprior}, 
      author={Johannes Ballé and David Minnen and Saurabh Singh and Sung Jin Hwang and Nick Johnston},
      year={2018},
      eprint={1802.01436},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/1802.01436}, 
}


@misc{Toderici16RNN,
      title={Full Resolution Image Compression with Recurrent Neural Networks}, 
      author={George Toderici and Damien Vincent and Nick Johnston and Sung Jin Hwang and David Minnen and Joel Shor and Michele Covell},
      year={2017},
      eprint={1608.05148},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1608.05148}, 
}


@misc{Agustsson18GAN,
      title={Generative Adversarial Networks for Extreme Learned Image Compression}, 
      author={Eirikur Agustsson and Michael Tschannen and Fabian Mentzer and Radu Timofte and Luc Van Gool},
      year={2019},
      eprint={1804.02958},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1804.02958}, 
}

@INPROCEEDINGS{Minnen20,
  author={Minnen, David and Singh, Saurabh},
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)}, 
  title={Channel-Wise Autoregressive Entropy Models for Learned Image Compression}, 
  year={2020},
  volume={},
  number={},
  pages={3339-3343},
  keywords={Entropy;Image coding;Codecs;Adaptation models;Predictive models;Bit rate;Training;Image Compression;Neural Networks;Adaptive Entropy Modeling},
  doi={10.1109/ICIP40778.2020.9190935}
}


@misc{He20Checkboard,
      title={Checkerboard Context Model for Efficient Learned Image Compression}, 
      author={Dailan He and Yaoyan Zheng and Baocheng Sun and Yan Wang and Hongwei Qin},
      year={2021},
      eprint={2103.15306},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2103.15306}, 
}

@misc{ELIC,
      title={ELIC: Efficient Learned Image Compression with Unevenly Grouped Space-Channel Contextual Adaptive Coding}, 
      author={Dailan He and Ziming Yang and Weikun Peng and Rui Ma and Hongwei Qin and Yan Wang},
      year={2022},
      eprint={2203.10886},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2203.10886}, 
}

@article{MLIC++,
author = {Jiang, Wei and Yang, Jiayu and Zhai, Yongqi and Gao, Feng and Wang, Ronggang},
title = {MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3719011},
doi = {10.1145/3719011},
abstract = {The latent representation in learned image compression encompasses channel-wise, local spatial, and global spatial correlations, which are essential for the entropy model to capture for conditional entropy minimization. Efficiently capturing these contexts within a single entropy model, especially in high-resolution image coding, presents a challenge due to the computational complexity of existing global context modules. To address this challenge, we propose the Linear Complexity Multi-Reference Entropy Model (MEM ({}^{++}) ). Specifically, the latent representation is partitioned into multiple slices. For channel-wise contexts, previously compressed slices serve as the context for compressing a particular slice. For local contexts, we introduce a shifted-window-based checkerboard attention module. This module ensures linear complexity without sacrificing performance. For global contexts, we propose a linear complexity attention mechanism. It captures global correlations by decomposing the softmax operation, enabling the implicit computation of attention maps from previously decoded slices. Using MEM++ as the entropy model, we develop the image compression method MLIC ({}^{++}) . Extensive experimental results demonstrate that MLIC ({}^{++})  achieves state-of-the-art performance, reducing BD-rate by  (13.39\%)  on the Kodak dataset compared to VTM-17.0 in Peak Signal-to-Noise Ratio (PSNR). Furthermore, MLIC ({}^{++})  exhibits linear computational complexity and memory consumption with resolution, making it highly suitable for high-resolution image coding. Code and pre-trained models are available at .},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
keywords = {Entropy Model, Learned Image Compression}
}

@misc{l1norm,
      title={Pruning Filters for Efficient ConvNets}, 
      author={Hao Li and Asim Kadav and Igor Durdanovic and Hanan Samet and Hans Peter Graf},
      year={2017},
      eprint={1608.08710},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1608.08710}, 
}


@misc{CBC,
      title={Coreset-Based Neural Network Compression}, 
      author={Abhimanyu Dubey and Moitreya Chatterjee and Narendra Ahuja},
      year={2018},
      eprint={1807.09810},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1807.09810}, 
}

@misc{Lin20HRank,
      title={HRank: Filter Pruning using High-Rank Feature Map}, 
      author={Mingbao Lin and Rongrong Ji and Yan Wang and Yichen Zhang and Baochang Zhang and Yonghong Tian and Ling Shao},
      year={2020},
      eprint={2002.10179},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2002.10179}, 
}

@misc{Sui21CHIP,
      title={CHIP: CHannel Independence-based Pruning for Compact Neural Networks}, 
      author={Yang Sui and Miao Yin and Yi Xie and Huy Phan and Saman Zonouz and Bo Yuan},
      year={2022},
      eprint={2110.13981},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2110.13981}, 
}

@inbook{AMC,
   title={AMC: AutoML for Model Compression and Acceleration on Mobile Devices},
   ISBN={9783030012342},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-030-01234-2_48},
   DOI={10.1007/978-3-030-01234-2_48},
   booktitle={Computer Vision – ECCV 2018},
   publisher={Springer International Publishing},
   author={He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
   year={2018},
   pages={815–832} 
}

@misc{DECORE,
      title={DECORE: Deep Compression with Reinforcement Learning}, 
      author={Manoj Alwani and Yang Wang and Vashisht Madhavan},
      year={2022},
      eprint={2106.06091},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.06091}, 
}

@misc{DMCP,
      title={DMCP: Differentiable Markov Channel Pruning for Neural Networks}, 
      author={Shaopeng Guo and Yujie Wang and Quanquan Li and Junjie Yan},
      year={2020},
      eprint={2005.03354},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2005.03354}, 
}

@misc{DSA,
      title={DSA: More Efficient Budgeted Pruning via Differentiable Sparsity Allocation}, 
      author={Xuefei Ning and Tianchen Zhao and Wenshuo Li and Peng Lei and Yu Wang and Huazhong Yang},
      year={2020},
      eprint={2004.02164},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2004.02164}, 
}

@ARTICLE{Shannon48,
  author={Shannon, C. E.},
  journal={The Bell System Technical Journal}, 
  title={A mathematical theory of communication}, 
  year={1948},
  volume={27},
  number={3},
  pages={379-423},
  keywords={},
  doi={10.1002/j.1538-7305.1948.tb01338.x}
}

@inproceedings{Shukla10Survey,
author = {Shukla, Jaya and Alwani, Manoj and Tiwari, Anil},
year = {2010},
month = {05},
pages = {V6-136 },
title = {A survey on lossless image compression methods},
volume = {6},
journal = {ICCET 2010 - 2010 International Conference on Computer Engineering and Technology, Proceedings},
doi = {10.1109/ICCET.2010.5486344}
}

@misc{BPG,
  author  = {Fabrice Bellard},
  title   = {BPG Image Format},
  url     = {https://bellard.org/bpg},
  year    = {2015},
  note    = {Accessed: 2015-01-07},
}

@INPROCEEDINGS{JPEG2000,
  author={Charrier, M. and Cruz, D.S. and Larsson, M.},
  booktitle={Proceedings IEEE International Conference on Multimedia Computing and Systems}, 
  title={JPEG2000, the next millennium compression standard for still images}, 
  year={1999},
  volume={1},
  number={},
  pages={131-132 vol.1},
  keywords={Transform coding;Image coding;Virtual manufacturing;Java;Decoding;Digital images;Propagation losses;Internet;Discrete wavelet transforms;Telecommunications},
  doi={10.1109/MMCS.1999.779134}
}

@misc{Ballé15GDN,
      title={Density Modeling of Images using a Generalized Normalization Transformation}, 
      author={Johannes Ballé and Valero Laparra and Eero P. Simoncelli},
      year={2016},
      eprint={1511.06281},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.06281}, 
}

@ARTICLE{CABAC,
  author={Marpe, D. and Schwarz, H. and Wiegand, T.},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Context-based adaptive binary arithmetic coding in the H.264/AVC video compression standard}, 
  year={2003},
  volume={13},
  number={7},
  pages={620-636},
  keywords={Arithmetic;Automatic voltage control;Video compression;Application software;ISO standards;IEC standards;Context modeling;Hardware;Entropy coding;Materials testing},
  doi={10.1109/TCSVT.2003.815173}
}

@misc{Theis17,
      title={Lossy Image Compression with Compressive Autoencoders}, 
      author={Lucas Theis and Wenzhe Shi and Andrew Cunningham and Ferenc Huszár},
      year={2017},
      eprint={1703.00395},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1703.00395}, 
}

@INPROCEEDINGS{MS-SSIM,
  author={Wang, Z. and Simoncelli, E.P. and Bovik, A.C.},
  booktitle={The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003}, 
  title={Multiscale structural similarity for image quality assessment}, 
  year={2003},
  volume={2},
  number={},
  pages={1398-1402 Vol.2},
  keywords={Image quality;Signal processing;Humans;Visual system;Data mining;Layout;Distortion measurement;Displays;Optical filters;Electric variables measurement},
  doi={10.1109/ACSSC.2003.1292216}
}

@article{MOS,
author = {Streijl, Robert and Hands, David},
year = {2016},
month = {03},
pages = {213-227},
title = {Mean opinion score (MOS) revisited: methods and applications, limitations and alternatives},
volume = {22},
journal = {Multimedia Systems},
doi = {10.1007/s00530-014-0446-1}
}

@misc{Minnen18,
      title={Joint Autoregressive and Hierarchical Priors for Learned Image Compression}, 
      author={David Minnen and Johannes Ballé and George Toderici},
      year={2018},
      eprint={1809.02736},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1809.02736}, 
}

@misc{Lee19,
      title={Context-adaptive Entropy Model for End-to-end Optimized Image Compression}, 
      author={Jooyoung Lee and Seunghyun Cho and Seung-Kwon Beack},
      year={2019},
      eprint={1809.10452},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/1809.10452}, 
}

@misc{Cheng20,
      title={Learned Image Compression with Discretized Gaussian Mixture Likelihoods and Attention Modules}, 
      author={Zhengxue Cheng and Heming Sun and Masaru Takeuchi and Jiro Katto},
      year={2020},
      eprint={2001.01568},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2001.01568}, 
}

@inproceedings{MLIC, 
    series={MM ’23},
   title={MLIC: Multi-Reference Entropy Model for Learned Image Compression},
   url={http://dx.doi.org/10.1145/3581783.3611694},
   DOI={10.1145/3581783.3611694},
   booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
   publisher={ACM},
   author={Jiang, Wei and Yang, Jiayu and Zhai, Yongqi and Ning, Peirong and Gao, Feng and Wang, Ronggang},
   year={2023},
   month=oct, pages={7618–7627},
   collection={MM ’23} 
}


@incollection{NJU21Survey,
  author    = {吴建鑫 and 王环宇 and 张永顺},
  title     = {结构化剪枝综述},
  editor    = {张敏灵 and 胡清华 and 李宇峰},
  booktitle = {机器学习及其应用(2021)},
  publisher = {清华大学出版社},
  year      = {2021},
  address   = {北京},
  language  = {chinese}
}

@article{He24Survey,
   title={Structured Pruning for Deep Convolutional Neural Networks: A Survey},
   volume={46},
   ISSN={1939-3539},
   url={http://dx.doi.org/10.1109/TPAMI.2023.3334614},
   DOI={10.1109/tpami.2023.3334614},
   number={5},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={He, Yang and Xiao, Lingao},
   year={2024},
   month=may, pages={2900–2919} 
}

@INPROCEEDINGS{FPGM,
  author={He, Yang and Liu, Ping and Wang, Ziwei and Hu, Zhilan and Yang, Yi},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration}, 
  year={2019},
  volume={},
  number={},
  pages={4335-4344},
  keywords={Deep Learning;Others},
  doi={10.1109/CVPR.2019.00447}
}

@misc{ThiNet,
      title={ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression}, 
      author={Jian-Hao Luo and Jianxin Wu and Weiyao Lin},
      year={2017},
      eprint={1707.06342},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1707.06342}, 
}

@misc{NISP,
      title={NISP: Pruning Networks using Neuron Importance Score Propagation}, 
      author={Ruichi Yu and Ang Li and Chun-Fu Chen and Jui-Hsin Lai and Vlad I. Morariu and Xintong Han and Mingfei Gao and Ching-Yung Lin and Larry S. Davis},
      year={2018},
      eprint={1711.05908},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1711.05908}, 
}



@misc{DDPG,
      title={Continuous control with deep reinforcement learning}, 
      author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
      year={2019},
      eprint={1509.02971},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1509.02971}, 
}

@BOOK{ADMM,
  author={Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
  booktitle={Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers},
  year={2011},
  volume={},
  number={},
  pages={},
  keywords={Artificial Intelligence;Machine Learning;Optimization and Control Theory;Computer Science},
  doi={10.1561/2200000016}
}

@misc{MetaPruning,
  title={MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning}, 
  author={Zechun Liu and Haoyuan Mu and Xiangyu Zhang and Zichao Guo and Xin Yang and Tim Kwang-Ting Cheng and Jian Sun},
  year={2019},
  eprint={1903.10258},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1903.10258}, 
}

@misc{ABCPruner,
      title={Channel Pruning via Automatic Structure Search}, 
      author={Mingbao Lin and Rongrong Ji and Yuxin Zhang and Baochang Zhang and Yongjian Wu and Yonghong Tian},
      year={2020},
      eprint={2001.08565},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2001.08565}, 
}


@article{ABC,
author = {Karaboga, Dervis},
year = {2005},
month = {01},
pages = {},
title = {An Idea Based on Honey Bee Swarm for Numerical Optimization, Technical Report - TR06},
journal = {Technical Report, Erciyes University}
}

@article{PyTorch,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@ARTICLE{Ahmed74DCT,
  author={Ahmed, N. and Natarajan, T. and Rao, K.R.},
  journal={IEEE Transactions on Computers}, 
  title={Discrete Cosine Transform}, 
  year={1974},
  volume={C-23},
  number={1},
  pages={90-93},
  keywords={Discrete cosine transform, discrete Fourier transform, feature selection, Haar transform, Karhunen-Loève transform, rate distortion, Walsh-Hadamard transform, Wiener vector and scalar filtering.},
  doi={10.1109/T-C.1974.223784}
}

@ARTICLE{Pearl72,
  author={Pearl, J. and Andrews, H. and Pratt, W.},
  journal={IEEE Transactions on Communications}, 
  title={Performance Measures for Transform Data Coding}, 
  year={1972},
  volume={20},
  number={3},
  pages={411-415},
  keywords={Demodulation;Phase locked loops;Signal synthesis;NASA;Frequency synchronization;Frequency modulation;Viterbi algorithm;Rate-distortion;Signal detection;Steady-state},
  doi={10.1109/TCOM.1972.1091168}
}

@misc{Ioffe15BN,
      title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}, 
      author={Sergey Ioffe and Christian Szegedy},
      year={2015},
      eprint={1502.03167},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1502.03167}, 
}

@article{Heeger92DN, 
    title={Normalization of cell responses in cat striate cortex}, 
    volume={9}, 
    DOI={10.1017/S0952523800009640}, 
    number={2}, 
    journal={Visual Neuroscience}, 
    author={Heeger, David J.}, 
    year={1992}, 
    pages={181–197}
}

@misc{STE,
      title={Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets}, 
      author={Penghang Yin and Jiancheng Lyu and Shuai Zhang and Stanley Osher and Yingyong Qi and Jack Xin},
      year={2019},
      eprint={1903.05662},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1903.05662}, 
}




@inproceedings{PixelCNN,
author = {Oord, A\"{a}ron van den and Kalchbrenner, Nal and Vinyals, Oriol and Espeholt, Lasse and Graves, Alex and Kavukcuoglu, Koray},
title = {Conditional image generation with PixelCNN decoders},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {4797–4805},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

@misc{PixelShuffle,
      title={Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network}, 
      author={Wenzhe Shi and Jose Caballero and Ferenc Huszár and Johannes Totz and Andrew P. Aitken and Rob Bishop and Daniel Rueckert and Zehan Wang},
      year={2016},
      eprint={1609.05158},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1609.05158}, 
}

@INPROCEEDINGS{GoogLeNet,
  author={Szegedy, Christian and Wei Liu and Yangqing Jia and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Going deeper with convolutions}, 
  year={2015},
  volume={},
  number={},
  pages={1-9},
  keywords={Computer architecture;Convolutional codes;Sparse matrices;Neural networks;Visualization;Object detection;Computer vision},
  doi={10.1109/CVPR.2015.7298594}
}

@misc{CompressAI,
      title={CompressAI: a PyTorch library and evaluation platform for end-to-end compression research}, 
      author={Jean Bégaint and Fabien Racapé and Simon Feltman and Akshay Pushparaja},
      year={2020},
      eprint={2011.03029},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2011.03029}, 
}

@article{ImageNet,
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
title = {ImageNet Large Scale Visual Recognition Challenge},
year = {2015},
issue_date = {December  2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {115},
number = {3},
issn = {0920-5691},
url = {https://doi.org/10.1007/s11263-015-0816-y},
doi = {10.1007/s11263-015-0816-y},
abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
journal = {Int. J. Comput. Vision},
month = dec,
pages = {211–252},
numpages = {42},
keywords = {Benchmark, Dataset, Large-scale, Object detection, Object recognition}
}

@misc{COCO2017,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1405.0312}, 
}

@INPROCEEDINGS{DIV2K,
  author={Agustsson, Eirikur and Timofte, Radu},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study}, 
  year={2017},
  volume={},
  number={},
  pages={1122-1131},
  keywords={Image resolution;Atmospheric measurements;Particle measurements;Image quality;Image restoration;Degradation;Agriculture},
  doi={10.1109/CVPRW.2017.150}
}

@misc{Flickr2K,
      title={Enhanced Deep Residual Networks for Single Image Super-Resolution}, 
      author={Bee Lim and Sanghyun Son and Heewon Kim and Seungjun Nah and Kyoung Mu Lee},
      year={2017},
      eprint={1707.02921},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1707.02921}, 
}

@misc{Kodak,
  author = {Franzen, Rich},
  title = {Dataset: Kodak lossless true color image suite},
  year = {2024},
  doi = {10.57702/pbp8d9mk},
  url = {https://r0k.us/graphics/kodak},
}



























